{"cells":[{"cell_type":"markdown","metadata":{"id":"Tce3stUlHN0L"},"source":["##### Copyright 2024 Google LLC."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"tuOe1ymfHZPu"},"outputs":[],"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"yeadDkMiISin"},"source":["# Gemini API: Quickstart with Python"]},{"cell_type":"markdown","metadata":{"id":"lEXQ3OwKIa-O"},"source":["\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n","  \u003ctd\u003e\n","    \u003ca target=\"_blank\" href=\"https://ai.google.dev/tutorials/python_quickstart\"\u003e\u003cimg src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" /\u003eView on Google AI\u003c/a\u003e\n","  \u003c/td\u003e\n","  \u003ctd\u003e\n","    \u003ca target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003eRun in Google Colab\u003c/a\u003e\n","  \u003c/td\u003e\n","  \u003ctd\u003e\n","    \u003ca target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003eView source on GitHub\u003c/a\u003e\n","  \u003c/td\u003e\n","\u003c/table\u003e"]},{"cell_type":"markdown","metadata":{"id":"uOxMUKTxR-_j"},"source":["This quickstart demonstrates how to use the Python SDK for the Gemini API, which gives you access to Google's Gemini large language models. In this quickstart, you will learn how to:\n","\n","1. Set up your development environment and API access to use Gemini.\n","2. Generate text responses from text inputs.\n","3. Generate text responses from multimodal inputs (text and images).\n","4. Use Gemini for multi-turn conversations (chat).\n","5. Use embeddings for large language models."]},{"cell_type":"markdown","metadata":{"id":"H9__zr1nSBpE"},"source":["## Prerequisites\n","\n","You can run this quickstart in [Google Colab](https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb), which runs this notebook directly in the browser and does not require additional environment configuration.\n","\n","Alternatively, to complete this quickstart locally, ensure that your development environment meets the following requirements:\n","\n","-  Python 3.9+\n","-  An installation of `jupyter` to run the notebook."]},{"cell_type":"markdown","metadata":{"id":"FFPBKLapSCkM"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"wFNV1e3ASJha"},"source":["### Install the Python SDK\n","\n","The Python SDK for the Gemini API, is contained in the [`google-generativeai`](https://pypi.org/project/google-generativeai/) package. Install the dependency using pip:"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15999,"status":"ok","timestamp":1713600610760,"user":{"displayName":"Reza Alawi","userId":"00051117565616982680"},"user_tz":-420},"id":"9OEoeosRTv-5"},"outputs":[],"source":["!pip install -q -U google-generativeai"]},{"cell_type":"markdown","metadata":{"id":"KCFF5VSTbcAR"},"source":["### Import packages"]},{"cell_type":"markdown","metadata":{"id":"vRC2HngneEeQ"},"source":["Import the necessary packages."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1031,"status":"ok","timestamp":1713600651773,"user":{"displayName":"Reza Alawi","userId":"00051117565616982680"},"user_tz":-420},"id":"TS9l5igubpHO"},"outputs":[],"source":["import pathlib\n","import textwrap\n","\n","import google.generativeai as genai\n","\n","from IPython.display import display\n","from IPython.display import Markdown\n","\n","\n","def to_markdown(text):\n","  text = text.replace('â€¢', '  *')\n","  return Markdown(textwrap.indent(text, '\u003e ', predicate=lambda _: True))"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":768,"status":"ok","timestamp":1713600661795,"user":{"displayName":"Reza Alawi","userId":"00051117565616982680"},"user_tz":-420},"id":"d10c38a5c91f"},"outputs":[],"source":["# Used to securely store your API key\n","from google.colab import userdata"]},{"cell_type":"markdown","metadata":{"id":"gHYFrFPjSGNq"},"source":["### Setup your API key\n","\n","Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n","\n","\u003ca class=\"button button-primary\" href=\"https://makersuite.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\"\u003eGet an API key\u003c/a\u003e"]},{"cell_type":"markdown","metadata":{"id":"tHhsUxDTdw0W"},"source":["In Colab, add the key to the secrets manager under the \"ðŸ”‘\" in the left panel. Give it the name `GOOGLE_API_KEY`."]},{"cell_type":"markdown","metadata":{"id":"VmSlTHXxb5pV"},"source":["Once you have the API key, pass it to the SDK. You can do this in two ways:\n","\n","* Put the key in the `GOOGLE_API_KEY` environment variable (the SDK will automatically pick it up from there).\n","* Pass the key to `genai.configure(api_key=...)`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ab9ASynfcIZn"},"outputs":[],"source":["# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n","GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n","\n","genai.configure(api_key=GOOGLE_API_KEY)"]},{"cell_type":"markdown","metadata":{"id":"8ssbTMNVSMd-"},"source":["## List models\n","\n","Now you're ready to call the Gemini API. Use `list_models` to see the available Gemini models:\n","\n","* `gemini-pro`: optimized for text-only prompts.\n","* `gemini-pro-vision`: optimized for text-and-images prompts."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"elapsed":1744,"status":"ok","timestamp":1713356541499,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"QvvWFy08e5c5","outputId":"cb0a9b30-fc5c-49e4-fa78-fef177a600b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["models/gemini-1.0-pro\n","models/gemini-1.0-pro-001\n","models/gemini-1.0-pro-latest\n","models/gemini-1.0-pro-vision-latest\n","models/gemini-1.5-pro-latest\n","models/gemini-pro\n","models/gemini-pro-vision\n"]}],"source":["for m in genai.list_models():\n","  if 'generateContent' in m.supported_generation_methods:\n","    print(m.name)"]},{"cell_type":"markdown","metadata":{"id":"FTl5NjtrhA0J"},"source":["Note: For detailed information about the available models, including their capabilities and rate limits, see [Gemini models](https://ai.google.dev/models/gemini). There are options for requesting [rate limit increases](https://ai.google.dev/docs/increase_quota). The rate limit for Gemini-Pro models is 60 requests per minute (RPM).\n","\n","The `genai` package also supports the PaLM  family of models, but only the Gemini models support the generic, multimodal capabilities of the `generateContent` method."]},{"cell_type":"markdown","metadata":{"id":"LZfoK3I3hu6V"},"source":["## Generate text from text inputs\n","\n","For text-only prompts, use the `gemini-pro` model:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2bcfnGEviwTI"},"outputs":[],"source":["model = genai.GenerativeModel('gemini-pro')"]},{"cell_type":"markdown","metadata":{"id":"WR_2A_sxk8sK"},"source":["The `generate_content` method can handle a wide variety of use cases, including multi-turn chat and multimodal input, depending on what the underlying model supports. The available models only support text and images as input, and text as output.\n","\n","In the simplest case, you can pass a prompt string to the \u003ca href=\"https://ai.google.dev/api/python/google/generativeai/GenerativeModel#generate_content\"\u003e\u003ccode\u003eGenerativeModel.generate_content\u003c/code\u003e\u003c/a\u003e method:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"elapsed":9542,"status":"ok","timestamp":1713356618533,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"he-OfzBbhACQ","outputId":"6ec35f37-8fbf-48e5-b211-e9dcbc077fa1"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 114 ms, sys: 16.5 ms, total: 130 ms\n","Wall time: 9.22 s\n"]}],"source":["%%time\n","response = model.generate_content(\"What is the meaning of life?\")"]},{"cell_type":"markdown","metadata":{"id":"FbrR-n_qlpFd"},"source":["In simple cases, the `response.text` accessor is all you need. To display formatted Markdown text, use the `to_markdown` function:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":480},"executionInfo":{"elapsed":327,"status":"ok","timestamp":1713356638852,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"G-zBkueElVEO","outputId":"a3ed027c-bb05-4eea-ee64-85488156f23d"},"outputs":[{"data":{"text/markdown":"\u003e The meaning of life is a deeply personal and subjective question that has been pondered by philosophers, theologians, and scientists for centuries. There is no single answer that satisfies everyone, as the meaning of life can vary greatly depending on individual beliefs, values, and experiences.\n\u003e \n\u003e Some common perspectives on the meaning of life include:\n\u003e \n\u003e * **Purpose-driven:** Life has an inherent purpose or goal, such as pursuing happiness, achieving personal growth, or contributing to the well-being of others.\n\u003e * **Experiential:** Life is about enjoying the present moment and savoring the unique experiences it offers.\n\u003e * **Relationship-oriented:** Life is primarily about forming and maintaining meaningful connections with others.\n\u003e * **Spiritual:** Life has a deeper, non-material dimension that involves connecting with a higher power or experiencing a sense of transcendence.\n\u003e * **Evolutionary:** Life is part of a larger evolutionary process that involves adapting to changing circumstances and creating new possibilities.\n\u003e \n\u003e Ultimately, the meaning of life is something that each individual must discover for themselves. There is no right or wrong answer, and the meaning of life can evolve and change over time.\n\u003e \n\u003e Here are some additional insights on the meaning of life:\n\u003e \n\u003e * **Find what brings you joy and fulfillment:** Pursue activities, relationships, and goals that make you feel alive and happy.\n\u003e * **Live in the present moment:** Don't dwell on the past or worry about the future. Focus on appreciating the present moment and savoring your experiences.\n\u003e * **Connect with others:** Build strong relationships with loved ones, friends, and community members.\n\u003e * **Make a meaningful contribution:** Find ways to contribute to your community or society, whether through volunteering, advocacy, or simply being a kind and helpful person.\n\u003e * **Seek knowledge and understanding:** Continuously learn and grow throughout your life. Explore the world with curiosity and seek to understand the mysteries of existence.\n\u003e * **Be kind to yourself and others:** Show compassion and understanding towards yourself and those around you. Remember that everyone is on their own unique journey.\n\u003e \n\u003e The meaning of life is a lifelong inquiry. It's a journey of self-discovery, growth, and connection that can lead to a fulfilling and meaningful existence.","text/plain":["\u003cIPython.core.display.Markdown object\u003e"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["to_markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"BEJupEDUo6Xj"},"source":["Gemini can generate multiple possible responses for a single prompt. These possible responses are called `candidates`, and you can review them to select the most suitable one as the response.\n","\n","View the response candidates with \u003ca href=\"https://ai.google.dev/api/python/google/ai/generativelanguage/GenerateContentResponse#candidates\"\u003e\u003ccode\u003eGenerateContentResponse.candidates\u003c/code\u003e\u003c/a\u003e:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":309,"status":"ok","timestamp":1713338024853,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"QoGYz-I7o5wF","outputId":"2c8e7fd0-d56f-4837-fb8a-b94a59ff54f9"},"outputs":[{"data":{"text/plain":["[content {\n","  parts {\n","    text: \"The meaning of life is a profound philosophical question that has been debated throughout history. There is no definitive answer, and different individuals and cultures have proposed various interpretations to give meaning to their existence. Here are a few common perspectives on the meaning of life:\\n\\n1. **Purpose-Driven:** This perspective suggests that life has an inherent purpose or goal. It may involve fulfilling a specific role or destiny, achieving personal growth, or contributing to the betterment of society.\\n\\n2. **Subjectivist:** According to this view, the meaning of life is subjective and unique to each individual. It is shaped by personal values, beliefs, experiences, and aspirations. Ultimately, individuals create their own meaning through their actions and choices.\\n\\n3. **Existentialist:** This perspective emphasizes the freedom and responsibility of individuals to create their own meaning in a meaningless universe. It highlights the importance of personal authenticity, self-determination, and embracing the absurdity of existence.\\n\\n4. **Scientific:** Some scientific perspectives on the meaning of life propose that it is a natural phenomenon driven by evolutionary forces. According to this view, the ultimate goal of life is to ensure the survival and reproduction of one\\'s genes.\\n\\n5. **Spiritual or Religious:** Many spiritual and religious beliefs provide a specific purpose or meaning to life. They often involve a connection to a higher power, a belief in an afterlife, or a moral code that guides actions and intentions.\\n\\n6. **Hedonistic:** This perspective suggests that the meaning of life lies in seeking pleasure and avoiding pain. It emphasizes personal gratification and enjoyment as the primary goals of existence.\\n\\n7. **Nihilistic:** This view proposes that life has no inherent meaning or purpose. It questions the value of existence and suggests that all efforts are ultimately futile and meaningless.\\n\\nIt\\'s important to note that these are just a few of the many perspectives on the meaning of life. Ultimately, the search for meaning is a personal journey, and each individual must discover what gives their life purpose and fulfillment.\"\n","  }\n","  role: \"model\"\n","}\n","finish_reason: STOP\n","index: 0\n","safety_ratings {\n","  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n","  probability: NEGLIGIBLE\n","}\n","safety_ratings {\n","  category: HARM_CATEGORY_HATE_SPEECH\n","  probability: NEGLIGIBLE\n","}\n","safety_ratings {\n","  category: HARM_CATEGORY_HARASSMENT\n","  probability: NEGLIGIBLE\n","}\n","safety_ratings {\n","  category: HARM_CATEGORY_DANGEROUS_CONTENT\n","  probability: NEGLIGIBLE\n","}\n","]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["response.candidates"]},{"cell_type":"markdown","metadata":{"id":"EJrwllLnHlBb"},"source":["By default, the model returns a response after completing the entire generation process. You can also stream the response as it is being generated, and the model will return chunks of the response as soon as they are generated.\n","\n","To stream responses, use \u003ca href=\"https://ai.google.dev/api/python/google/generativeai/GenerativeModel#generate_content\"\u003e\u003ccode\u003eGenerativeModel.generate_content(..., stream=True)\u003c/code\u003e\u003c/a\u003e."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"elapsed":5531,"status":"ok","timestamp":1713356900356,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"Z7n59b3hHo6-","outputId":"ee144bae-9f01-4e16-9c86-89816afc2c3b"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 67.3 ms, sys: 10.8 ms, total: 78.1 ms\n","Wall time: 5.22 s\n"]}],"source":["%%time\n","response = model.generate_content(\"What is the meaning of life?\", stream=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":354,"status":"ok","timestamp":1713356932588,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"2jt0d0GCIUhg","outputId":"72167d1a-4f21-4f55-c615-d2756af13739"},"outputs":[{"name":"stdout","output_type":"stream","text":["There is no one definitive answer to the question \"What is the meaning of life\n","________________________________________________________________________________\n","?\". Different people will have different answers, based on their own beliefs, values, and experiences. Some common answers to this question include:\n","\n","* To find happiness\n","________________________________________________________________________________\n"," and fulfillment\n","* To make a difference in the world\n","* To love and be loved\n","* To learn and grow\n","* To experience all that life has to offer\n","\n","Ultimately, the meaning of life is whatever you make it. There is no right or wrong answer, and the only person who can decide what is\n","________________________________________________________________________________\n"," meaningful to you is you.\n","________________________________________________________________________________\n"]}],"source":["for chunk in response:\n","  print(chunk.text)\n","  print(\"_\"*80)"]},{"cell_type":"markdown","metadata":{"id":"5b4Hkfj-pm3p"},"source":["When streaming, some response attributes are not available until you've iterated through all the response chunks. This is demonstrated below:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-URRx4chp0Kt"},"outputs":[],"source":["response = model.generate_content(\"What is the meaning of life?\", stream=True)"]},{"cell_type":"markdown","metadata":{"id":"mVaFQ4RmqGOH"},"source":["But attributes like \u003ccode\u003etext\u003c/code\u003e do not:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":320,"status":"ok","timestamp":1713356963644,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"TiRkS6nCqFmM","outputId":"e1f30d00-d9bd-4bb3-c938-2f863b4f7812"},"outputs":[{"name":"stdout","output_type":"stream","text":["IncompleteIterationError: Please let the response complete iteration before accessing the final accumulated\n","attributes (or call `response.resolve()`)\n"]}],"source":["try:\n","  response.text\n","except Exception as e:\n","  print(f'{type(e).__name__}: {e}')"]},{"cell_type":"markdown","metadata":{"id":"MCzr5ZpNhxLm"},"source":["## Generate text from image and text inputs\n","\n","Gemini provides a multimodal model (`gemini-pro-vision`) that accepts both text and images and inputs. The `GenerativeModel.generate_content` API is designed to handle multimodal prompts and returns a text output.\n","\n","Let's include an image:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":352,"status":"ok","timestamp":1713356996854,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"NtNGTBFF8Pgl","outputId":"40113c5f-47f2-4390-af06-049f62962121"},"outputs":[{"name":"stdout","output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  405k  100  405k    0     0  5419k      0 --:--:-- --:--:-- --:--:-- 5473k\n"]}],"source":["!curl -o image.jpg https://t0.gstatic.com/licensed-image?q=tbn:ANd9GcQ_Kevbk21QBRy-PgB4kQpS79brbmmEG7m3VOTShAn4PecDU5H5UxrJxE3Dw1JiaG17V88QIol19-3TM2wCHw"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1crXEjljBAliIcfRieAznB29Ay7iqz9CY"},"executionInfo":{"elapsed":5938,"status":"ok","timestamp":1713357019840,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"CjnS0vNTsVis","outputId":"1ff1728b-e0b1-4e14-8da4-5050af0253d7"},"outputs":[],"source":["import PIL.Image\n","\n","img = PIL.Image.open('image.jpg')\n","img"]},{"cell_type":"markdown","metadata":{"id":"7r99TN2R8EUD"},"source":["Use the `gemini-pro-vision` model and pass the image to the model with `generate_content`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EtXxgVzmJZzE"},"outputs":[],"source":["model = genai.GenerativeModel('gemini-pro-vision')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":62},"executionInfo":{"elapsed":7144,"status":"ok","timestamp":1713357050325,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"GwYifv298Cj3","outputId":"63c57d09-f31f-4f64-ce3e-80282089babb"},"outputs":[{"data":{"text/markdown":"\u003e  Chicken Teriyaki with brown rice, broccoli, and bell peppers.","text/plain":["\u003cIPython.core.display.Markdown object\u003e"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["response = model.generate_content(img)\n","\n","to_markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"7xW2Kyra8pSz"},"source":["To provide both text and images in a prompt, pass a list containing the strings and images:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vm9tUYeT8lBc"},"outputs":[],"source":["response = model.generate_content([\"Write a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\", img], stream=True)\n","response.resolve()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1713357130301,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"d46826OA9IDS","outputId":"f0b803a6-f16c-4531-8373-8a3ae882790c"},"outputs":[{"data":{"text/markdown":"\u003e  Meal prepping is a great way to save time and money, and it can also help you to eat healthier. This meal is a great example of a healthy and delicious meal that can be easily prepped ahead of time.\n\u003e \n\u003e This meal features brown rice, roasted vegetables, and chicken teriyaki. The brown rice is a whole grain that is high in fiber and nutrients. The roasted vegetables are a great way to get your daily dose of vitamins and minerals. And the chicken teriyaki is a delicious and protein-rich option that will keep you feeling full and satisfied.\n\u003e \n\u003e To make this meal, simply cook the brown rice according to the package directions. While the rice is cooking, roast the vegetables in the oven. And finally, cook the chicken teriyaki in a skillet. Once everything is cooked, assemble the meals into containers and store them in the refrigerator.\n\u003e \n\u003e This meal is perfect for busy people who want to eat healthy. It can be easily reheated and enjoyed on the go. And it is also a great option for meal prepping for the week.","text/plain":["\u003cIPython.core.display.Markdown object\u003e"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["to_markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"zsIZmCYVTDHD"},"source":["## Chat conversations\n","\n","Gemini enables you to have freeform conversations across multiple turns. The `ChatSession` class simplifies the process by managing the state of the conversation, so unlike with `generate_content`, you do not have to store the conversation history as a list.\n","\n","Initialize the chat:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1713357287183,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"y8B9Mwo-TCr2","outputId":"82a45473-b4af-4307-de8b-a5a61d832e6d"},"outputs":[{"data":{"text/plain":["ChatSession(\n","    model=genai.GenerativeModel(\n","        model_name='models/gemini-pro',\n","        generation_config={},\n","        safety_settings={},\n","        tools=None,\n","        system_instruction=None,\n","    ),\n","    history=[]\n",")"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["model = genai.GenerativeModel('gemini-pro')\n","chat = model.start_chat(history=[])\n","chat"]},{"cell_type":"markdown","metadata":{"id":"88Il02N-km9j"},"source":["Note: The vision model `gemini-pro-vision` is not optimized for multi-turn chat."]},{"cell_type":"markdown","metadata":{"id":"5odluV7kKbgr"},"source":["The `ChatSession.send_message` method returns the same `GenerateContentResponse` type as \u003ca href=\"https://ai.google.dev/api/python/google/generativeai/GenerativeModel#generate_content\"\u003e\u003ccode\u003eGenerativeModel.generate_content\u003c/code\u003e\u003c/a\u003e. It also appends your message and the response to the chat history:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"executionInfo":{"elapsed":3941,"status":"ok","timestamp":1713357351715,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"b72zbOEjKRxP","outputId":"709852c1-adf4-46aa-ce90-b91ee8ea55d6"},"outputs":[{"data":{"text/markdown":"\u003e Computers are like magical boxes that can take in information, process it, and then show the results on a screen, like a magic show with numbers and words!","text/plain":["\u003cIPython.core.display.Markdown object\u003e"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["response = chat.send_message(\"In one sentence, explain how a computer works to a young child.\")\n","to_markdown(response.text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1713357364126,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"5-5HS2bTOTU9","outputId":"78e0ffb6-1518-4ce8-9155-3374c1190b55"},"outputs":[{"data":{"text/plain":["[parts {\n","   text: \"In one sentence, explain how a computer works to a young child.\"\n"," }\n"," role: \"user\",\n"," parts {\n","   text: \"Computers are like magical boxes that can take in information, process it, and then show the results on a screen, like a magic show with numbers and words!\"\n"," }\n"," role: \"model\"]"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["chat.history"]},{"cell_type":"markdown","metadata":{"id":"7JaiFSIvOcVb"},"source":["You can keep sending messages to continue the conversation. Use the `stream=True` argument to stream the chat:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"elapsed":3730,"status":"ok","timestamp":1713357388861,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"Vxku7mzSObfZ","outputId":"b99b183e-93c4-413c-c019-eb005083eb73"},"outputs":[{"name":"stdout","output_type":"stream","text":["At its core, a computer is a machine that can receive, store, process\n","________________________________________________________________________________\n",", and output data according to a set of instructions, known as a program. The data is represented digitally, using a binary system of 0s and \n","________________________________________________________________________________\n","1s. The computer's hardware, including the processor, memory, and storage devices, works in conjunction with the software, which includes the operating system and applications, to execute the instructions and perform the desired tasks. Input devices such as keyboards and mice allow users to interact with the computer and provide instructions, while output\n","________________________________________________________________________________\n"," devices such as monitors and printers display or produce the results of the processing. The computer's ability to perform complex calculations and operations rapidly and reliably makes it a powerful tool for various tasks, from scientific research to entertainment.\n","________________________________________________________________________________\n"]}],"source":["response = chat.send_message(\"Okay, how about a more detailed explanation to a high schooler?\", stream=True)\n","\n","for chunk in response:\n","  print(chunk.text)\n","  print(\"_\"*80)"]},{"cell_type":"markdown","metadata":{"id":"AwCqtZ6D4kvk"},"source":["`glm.Content` objects contain a list of `glm.Part` objects that each contain either a text (string) or inline_data (`glm.Blob`), where a blob contains binary data and a `mime_type`. The chat history is available as a list of `glm.Content` objects in `ChatSession.history`:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"executionInfo":{"elapsed":572,"status":"ok","timestamp":1713357394414,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"WvyTmbC2d0k3","outputId":"1c63a7d5-2b26-40f4-8219-4565d6c751b4"},"outputs":[{"data":{"text/markdown":"\u003e **user**: In one sentence, explain how a computer works to a young child.","text/plain":["\u003cIPython.core.display.Markdown object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":"\u003e **model**: Computers are like magical boxes that can take in information, process it, and then show the results on a screen, like a magic show with numbers and words!","text/plain":["\u003cIPython.core.display.Markdown object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":"\u003e **user**: Okay, how about a more detailed explanation to a high schooler?","text/plain":["\u003cIPython.core.display.Markdown object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/markdown":"\u003e **model**: At its core, a computer is a machine that can receive, store, process, and output data according to a set of instructions, known as a program. The data is represented digitally, using a binary system of 0s and 1s. The computer's hardware, including the processor, memory, and storage devices, works in conjunction with the software, which includes the operating system and applications, to execute the instructions and perform the desired tasks. Input devices such as keyboards and mice allow users to interact with the computer and provide instructions, while output devices such as monitors and printers display or produce the results of the processing. The computer's ability to perform complex calculations and operations rapidly and reliably makes it a powerful tool for various tasks, from scientific research to entertainment.","text/plain":["\u003cIPython.core.display.Markdown object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["for message in chat.history:\n","  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))"]},{"cell_type":"markdown","metadata":{"id":"AEgVOYu0pAr4"},"source":["## Count tokens\n","\n","Large language models have a context window, and the context length is often measured in terms of the **number of tokens**. With the Gemini API, you can determine the number of tokens per any `glm.Content` object. In the simplest case, you can pass a query string to the `GenerativeModel.count_tokens` method as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":1511,"status":"ok","timestamp":1713357491256,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"eLjBmPCLpElk","outputId":"ff0117ec-2266-4601-c16f-ee357a0d30ef"},"outputs":[{"data":{"text/plain":["total_tokens: 7"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["model.count_tokens(\"What is the meaning of life?\")"]},{"cell_type":"markdown","metadata":{"id":"oM2_U8pmpHQA"},"source":["Similarly, you can check `token_count` for your `ChatSession`:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":2383,"status":"ok","timestamp":1713357869575,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"i0MUU4BZpG4_","outputId":"620612fe-8df4-4cf2-af60-0e40931d27a8"},"outputs":[{"data":{"text/plain":["total_tokens: 220"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["model.count_tokens(chat.history)"]},{"cell_type":"markdown","metadata":{"id":"f9bU0J3vUIbz"},"source":["## Use embeddings"]},{"cell_type":"markdown","metadata":{"id":"BpHIRU5bj7aW"},"source":["[Embedding](https://developers.google.com/machine-learning/glossary#embedding-vector) is a technique used to represent information as a list of floating point numbers in an array. With Gemini, you can represent text (words, sentences, and blocks of text) in a vectorized form, making it easier to compare and contrast embeddings. For example, two texts that share a similar subject matter or sentiment should have similar embeddings, which can be identified through mathematical comparison techniques such as cosine similarity. For more on how and why you should use embeddings, refer to the [Embeddings guide](https://ai.google.dev/docs/embeddings_guide).\n","\n","Use the `embed_content` method to generate embeddings. The method handles embedding for the following tasks (`task_type`):\n","\n","Task Type | Description\n","---       | ---\n","RETRIEVAL_QUERY\t| Specifies the given text is a query in a search/retrieval setting.\n","RETRIEVAL_DOCUMENT | Specifies the given text is a document in a search/retrieval setting. Using this task type requires a `title`.\n","SEMANTIC_SIMILARITY\t| Specifies the given text will be used for Semantic Textual Similarity (STS).\n","CLASSIFICATION\t| Specifies that the embeddings will be used for classification.\n","CLUSTERING\t| Specifies that the embeddings will be used for clustering.\n","\n","The following generates an embedding for a single string for document retrieval:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"elapsed":1538,"status":"ok","timestamp":1713358175446,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"hskqSKnJUHvp","outputId":"91ba1be1-8ae6-4448-c669-6800838b5101"},"outputs":[{"name":"stdout","output_type":"stream","text":["[-0.003216741, -0.013358698, -0.017649598, -0.0091 ... TRIMMED]\n"]},{"data":{"text/plain":["768"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["result = genai.embed_content(\n","    model=\"models/embedding-001\",\n","    content=\"What is the meaning of life?\",\n","    task_type=\"retrieval_document\",\n","    title=\"Embedding of single string\")\n","\n","# 1 input \u003e 1 vector output\n","print(str(result['embedding'])[:50], '... TRIMMED]')"]},{"cell_type":"markdown","metadata":{"id":"OcSc3KfflBCQ"},"source":["Note: The `retrieval_document` task type is the only task that accepts a title.\n","\n","To handle batches of strings, pass a list of strings in `content`:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"elapsed":2304,"status":"ok","timestamp":1713358202226,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"OnyD-Joik8LE","outputId":"16e8d18a-5579-4853-9241-2e0c67ec096a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.0040260437, 0.004124458, -0.014209415, -0.00183 ... TRIMMED ...\n","[-0.004049845, -0.0075574904, -0.0073463684, -0.03 ... TRIMMED ...\n","[0.025310587, -0.0080734305, -0.029902633, 0.01160 ... TRIMMED ...\n"]}],"source":["result = genai.embed_content(\n","    model=\"models/embedding-001\",\n","    content=[\n","      'What is the meaning of life?',\n","      'How much wood would a woodchuck chuck?',\n","      'How does the brain work?'],\n","    task_type=\"retrieval_document\",\n","    title=\"Embedding of list of strings\")\n","\n","# A list of inputs \u003e A list of vectors output\n","for v in result['embedding']:\n","  print(str(v)[:50], '... TRIMMED ...')"]},{"cell_type":"markdown","metadata":{"id":"zBg0eNeml3d4"},"source":["While the `genai.embed_content` function accepts simple strings or lists of strings, it is actually built around the `glm.Content` type (like \u003ca href=\"https://ai.google.dev/api/python/google/generativeai/GenerativeModel#generate_content\"\u003e\u003ccode\u003eGenerativeModel.generate_content\u003c/code\u003e\u003c/a\u003e). `glm.Content` objects are the primary units of conversation in the API.\n","\n","While the `glm.Content` object is multimodal, the `embed_content` method only supports text embeddings. This design gives the API the *possibility* to expand to multimodal embeddings."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":377,"status":"ok","timestamp":1713358250502,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"1-wmapZznXrm","outputId":"003b0c99-7a71-4601-f1c9-8612e77a51d0"},"outputs":[{"data":{"text/plain":["parts {\n","  text: \"At its core, a computer is a machine that can receive, store, process, and output data according to a set of instructions, known as a program. The data is represented digitally, using a binary system of 0s and 1s. The computer\\'s hardware, including the processor, memory, and storage devices, works in conjunction with the software, which includes the operating system and applications, to execute the instructions and perform the desired tasks. Input devices such as keyboards and mice allow users to interact with the computer and provide instructions, while output devices such as monitors and printers display or produce the results of the processing. The computer\\'s ability to perform complex calculations and operations rapidly and reliably makes it a powerful tool for various tasks, from scientific research to entertainment.\"\n","}\n","role: \"model\""]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["response.candidates[0].content"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":2606,"status":"ok","timestamp":1713358272732,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"cvX5jsrcnufk","outputId":"4222d577-8b0f-4ca4-9d83-dcd3c8e49a7a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.004268172, -0.05404532, 0.006941826, 0.03186704 ... TRIMMED ...\n"]}],"source":["result = genai.embed_content(\n","    model = 'models/embedding-001',\n","    content = response.candidates[0].content)\n","\n","# 1 input \u003e 1 vector output\n","print(str(result['embedding'])[:50], '... TRIMMED ...')"]},{"cell_type":"markdown","metadata":{"id":"jU8juHCxoUKG"},"source":["Similarly, the chat history contains a list of `glm.Content` objects, which you can pass directly to the `embed_content` function:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":438,"status":"ok","timestamp":1713358287247,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"ur5ajPsdnCON","outputId":"7a800c6e-91a6-49ca-8c1e-d2a3359004e9"},"outputs":[{"data":{"text/plain":["[parts {\n","   text: \"In one sentence, explain how a computer works to a young child.\"\n"," }\n"," role: \"user\",\n"," parts {\n","   text: \"Computers are like magical boxes that can take in information, process it, and then show the results on a screen, like a magic show with numbers and words!\"\n"," }\n"," role: \"model\",\n"," parts {\n","   text: \"Okay, how about a more detailed explanation to a high schooler?\"\n"," }\n"," role: \"user\",\n"," parts {\n","   text: \"At its core, a computer is a machine that can receive, store, process, and output data according to a set of instructions, known as a program. The data is represented digitally, using a binary system of 0s and 1s. The computer\\'s hardware, including the processor, memory, and storage devices, works in conjunction with the software, which includes the operating system and applications, to execute the instructions and perform the desired tasks. Input devices such as keyboards and mice allow users to interact with the computer and provide instructions, while output devices such as monitors and printers display or produce the results of the processing. The computer\\'s ability to perform complex calculations and operations rapidly and reliably makes it a powerful tool for various tasks, from scientific research to entertainment.\"\n"," }\n"," role: \"model\"]"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["chat.history"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"executionInfo":{"elapsed":2781,"status":"ok","timestamp":1713358304117,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"Z3xDB1hwof96","outputId":"ddb40513-2720-4bf1-95a0-2bc829d72220"},"outputs":[{"name":"stdout","output_type":"stream","text":["[-0.014632266, -0.042202696, -0.015757175, 0.01548 ... TRIMMED...\n","[-0.03287797, -0.02026918, 0.010579022, 0.03113971 ... TRIMMED...\n","[-0.010055617, -0.07208932, -0.00011750793, -0.023 ... TRIMMED...\n","[0.004268172, -0.05404532, 0.006941826, 0.03186704 ... TRIMMED...\n"]}],"source":["result = genai.embed_content(\n","    model = 'models/embedding-001',\n","    content = chat.history)\n","\n","# 1 input \u003e 1 vector output\n","for i,v in enumerate(result['embedding']):\n","  print(str(v)[:50], '... TRIMMED...')"]},{"cell_type":"markdown","metadata":{"id":"vuz9-TWDzdlb"},"source":["## Advanced use cases\n","\n","The following sections discuss advanced use cases and lower-level details of the Python SDK for the Gemini API."]},{"cell_type":"markdown","metadata":{"id":"o5FWJPSD1qFE"},"source":["### Safety settings\n","\n","The `safety_settings` argument lets you configure what the model blocks and allows in both prompts and responses. By default, safety settings block content with medium and/or high probability of being unsafe content across all dimensions. Learn more about [Safety settings](https://ai.google.dev/docs/safety_setting).\n","\n","Enter a questionable prompt and run the model with the default safety settings, and it will not return any candidates:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"elapsed":2403,"status":"ok","timestamp":1713358346470,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"VR1fp12I1yH0","outputId":"eeb5b58b-428f-481b-8213-7b549f2b8495"},"outputs":[{"data":{"text/plain":["[content {\n","  parts {\n","    text: \"I am not comfortable answering this question.\"\n","  }\n","  role: \"model\"\n","}\n","finish_reason: STOP\n","index: 0\n","safety_ratings {\n","  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n","  probability: NEGLIGIBLE\n","}\n","safety_ratings {\n","  category: HARM_CATEGORY_HATE_SPEECH\n","  probability: NEGLIGIBLE\n","}\n","safety_ratings {\n","  category: HARM_CATEGORY_HARASSMENT\n","  probability: NEGLIGIBLE\n","}\n","safety_ratings {\n","  category: HARM_CATEGORY_DANGEROUS_CONTENT\n","  probability: NEGLIGIBLE\n","}\n","]"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["response = model.generate_content('[Questionable prompt here]')\n","response.candidates"]},{"cell_type":"markdown","metadata":{"id":"YtPC1Fo514ec"},"source":["Now provide the same prompt to the model with newly configured safety settings, and you may get a response."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":2415,"status":"ok","timestamp":1713338382303,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"0UIt5LKp16jL","outputId":"097dfd04-ed27-4136-9fa8-68a8d06572cf"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"I'm sorry, but I'm not able to provide responses that are sexually suggestive in nature. Please provide a different prompt that is appropriate for our interaction.\""]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["response = model.generate_content('[Questionable prompt here]',\n","                                  safety_settings={'HARASSMENT':'block_none'})\n","response.text"]},{"cell_type":"markdown","metadata":{"id":"WE_f5EruGUnj"},"source":["Also note that each candidate has its own `safety_ratings`, in case the prompt passes but the individual responses fail the safety checks."]},{"cell_type":"markdown","metadata":{"id":"Ipa-8leY6wsK"},"source":["### Encode messages"]},{"cell_type":"markdown","metadata":{"id":"3r47nsUOn6YY"},"source":["The previous sections relied on the SDK to make it easy for you to send prompts to the API. This section offers a fully-typed equivalent to the previous example, so you can better understand the lower-level details regarding how the SDK encodes messages."]},{"cell_type":"markdown","metadata":{"id":"-fthdIItnqki"},"source":["Underlying the Python SDK is the \u003ca href=\"https://ai.google.dev/api/python/google/ai/generativelanguage\"\u003e\u003ccode\u003egoogle.ai.generativelanguage\u003c/code\u003e\u003c/a\u003e client library:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l6aafWECnpX6"},"outputs":[],"source":["import google.ai.generativelanguage as glm"]},{"cell_type":"markdown","metadata":{"id":"gm1RWcB3n_n0"},"source":["The SDK attempts to convert your message to a `glm.Content` object, which contains a list of `glm.Part` objects that each contain either:\n","\n","1. a \u003ca href=\"https://www.tensorflow.org/text/api_docs/python/text\"\u003e\u003ccode\u003etext\u003c/code\u003e\u003c/a\u003e (string)\n","2. `inline_data` (`glm.Blob`), where a blob contains binary `data` and a `mime_type`.\n","\n","You can also pass any of these classes as an equivalent dictionary.\n","\n","Note: The only accepted mime types are some image types, `image/*`.\n","\n","So, the fully-typed equivalent to the previous example is:  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IqFXdgDFRvlU"},"outputs":[],"source":["model = genai.GenerativeModel('gemini-pro-vision')\n","response = model.generate_content(\n","    glm.Content(\n","        parts = [\n","            glm.Part(text=\"Write a short, engaging blog post based on this picture.\"),\n","            glm.Part(\n","                inline_data=glm.Blob(\n","                    mime_type='image/jpeg',\n","                    data=pathlib.Path('image.jpg').read_bytes()\n","                )\n","            ),\n","        ],\n","    ),\n","    stream=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":62},"executionInfo":{"elapsed":418,"status":"ok","timestamp":1713358542090,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"wKithEbeRzDX","outputId":"e0952bfa-55bc-42fe-a985-c7f688af205e"},"outputs":[{"data":{"text/markdown":"\u003e I am not comfortable answering this question.... [TRIMMED] ...","text/plain":["\u003cIPython.core.display.Markdown object\u003e"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["response.resolve()\n","\n","to_markdown(response.text[:100] + \"... [TRIMMED] ...\")"]},{"cell_type":"markdown","metadata":{"id":"MBqknExlzn0k"},"source":["### Multi-turn conversations\n","\n","While the `genai.ChatSession` class shown earlier can handle many use cases, it does make some assumptions. If your use case doesn't fit into this chat implementation it's good to remember that `genai.ChatSession` is just a wrapper around \u003ca href=\"https://ai.google.dev/api/python/google/generativeai/GenerativeModel#generate_content\"\u003e\u003ccode\u003eGenerativeModel.generate_content\u003c/code\u003e\u003c/a\u003e. In addition to single requests, it can handle multi-turn conversations.\n","\n","The individual messages are `glm.Content` objects or compatible dictionaries, as seen in previous sections. As a dictionary, the message requires `role` and `parts` keys. The `role` in a conversation can either be the `user`, which provides the prompts, or `model`, which provides the responses.\n","\n","Pass a list of `glm.Content` objects and it will be treated as multi-turn chat:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":277},"executionInfo":{"elapsed":5304,"status":"ok","timestamp":1713358622331,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"LtfwMa0HzvZL","outputId":"c8aa3fb3-ca8a-45e8-cd37-49ff02e71240"},"outputs":[{"data":{"text/markdown":"\u003e Imagine your computer as a magic box with a special friend inside called the \"brain.\"\n\u003e \n\u003e * **The brain:** It's like a super smart person who knows everything and helps you do all the amazing things on the computer.\n\u003e * **The screen:** It's like a window that shows you the brain's thoughts and what it's working on.\n\u003e * **The keyboard and mouse:** They're like your buttons and tools that let you talk to the brain and tell it what you want to do.\n\u003e * **The inside of the box:** It's full of special parts that help the brain work its magic.\n\u003e \n\u003e When you press buttons on the keyboard or move the mouse, you're sending messages to the brain. It reads those messages and uses its special powers to:\n\u003e \n\u003e * Show you pictures and videos on the screen.\n\u003e * Let you play games and learn new things.\n\u003e * Help you do your homework or write stories.\n\u003e \n\u003e So, the computer is like a super smart friend who does everything you tell it to do, using its magic brain and special parts. It's like having a superpower helper in a box!","text/plain":["\u003cIPython.core.display.Markdown object\u003e"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["model = genai.GenerativeModel('gemini-pro')\n","\n","messages = [\n","    {'role':'user',\n","     'parts': [\"Briefly explain how a computer works to a young child.\"]}\n","]\n","response = model.generate_content(messages)\n","\n","to_markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"3mqqiDJvzyac"},"source":["To continue the conversation, add the response and another message.\n","\n","Note: For multi-turn conversations, you need to send the whole conversation history with each request. The API is **stateless**."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":555},"executionInfo":{"elapsed":9000,"status":"ok","timestamp":1713358647088,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"MBxsZBxcz5Ik","outputId":"798853f2-f992-482c-fb69-e60ef933b943"},"outputs":[{"data":{"text/markdown":"\u003e **How a Computer Works**\n\u003e \n\u003e At its core, a computer is an electronic device that can be programmed to carry out a set of instructions. It consists of hardware and software components that work together to process data, perform calculations, and store and retrieve information.\n\u003e \n\u003e **Hardware Components:**\n\u003e \n\u003e * **Central Processing Unit (CPU):** The \"brain\" of the computer that executes instructions and performs calculations.\n\u003e * **Memory (RAM):** Stores data and instructions that are currently being processed by the CPU.\n\u003e * **Storage Devices (HDD/SSD):** Stores data and programs permanently, even when the computer is turned off.\n\u003e * **Input Devices (Keyboard, Mouse):** Allow the user to interact with the computer and provide input.\n\u003e * **Output Devices (Monitor, Printer):** Display or print the results of computations or data.\n\u003e \n\u003e **Software Components:**\n\u003e \n\u003e * **Operating System (OS):** Manages the hardware and provides a user interface for interacting with the computer.\n\u003e * **Applications:** Software programs that perform specific tasks, such as word processing, web browsing, or playing games.\n\u003e \n\u003e **How a Computer Works:**\n\u003e \n\u003e 1. **Input:** The user provides input through input devices (e.g., typing on the keyboard).\n\u003e 2. **Processing:** The CPU reads the input and executes the appropriate instructions based on the program running.\n\u003e 3. **Memory Management:** The CPU manages the data and instructions in memory, ensuring that they are accessible when needed.\n\u003e 4. **Storage:** Data and programs are stored on storage devices for long-term access.\n\u003e 5. **Output:** The results of the processing are displayed on output devices (e.g., on the monitor) or printed.\n\u003e \n\u003e **Additional Concepts:**\n\u003e \n\u003e * **Binary Code:** Computers store and process data as binary digits (0s and 1s).\n\u003e * **Networking:** Computers can be connected to each other and to the internet to share data and resources.\n\u003e * **Cloud Computing:** Data and applications can be stored and accessed remotely over the internet instead of being stored locally on the computer.\n\u003e \n\u003e In summary, a computer is a combination of hardware and software that processes data, performs calculations, and stores and retrieves information based on instructions provided by the user. It allows us to interact with digital content, communicate with others, and accomplish a wide range of tasks.","text/plain":["\u003cIPython.core.display.Markdown object\u003e"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["messages.append({'role':'model',\n","                 'parts':[response.text]})\n","\n","messages.append({'role':'user',\n","                 'parts':[\"Okay, how about a more detailed explanation to a high school student?\"]})\n","\n","response = model.generate_content(messages)\n","\n","to_markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"4spL8SJ10ir7"},"source":["### Generation configuration\n","\n","The `generation_config` argument allows you to modify the generation parameters. Every prompt you send to the model includes parameter values that control how the model generates responses."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gE7I9Anl0ud7"},"outputs":[],"source":["model = genai.GenerativeModel('gemini-pro')\n","response = model.generate_content(\n","    'Tell me a story about a magic backpack.',\n","    generation_config=genai.types.GenerationConfig(\n","        # Only one candidate for now.\n","        candidate_count=1,\n","        stop_sequences=['x'],\n","        max_output_tokens=20,\n","        temperature=1.0),\n","    stream=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":62},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1713358850128,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"0fbab01e8fcf","outputId":"1e61ac03-3cd2-4516-aeba-948d1270f068"},"outputs":[{"data":{"text/markdown":"\u003e In the bustling city of Willow Creek, resided a curious and imaginative girl named Anya...","text/plain":["\u003cIPython.core.display.Markdown object\u003e"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["response.resolve()\n","text = response.text\n","\n","if response.candidates[0].finish_reason.name == \"MAX_TOKENS\":\n","    text += '...'\n","\n","to_markdown(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1713358890300,"user":{"displayName":"Joan Santoso","userId":"12048018563631236955"},"user_tz":-420},"id":"HYh9Epgg9jtw","outputId":"44eebb5a-4be4-49e2-b6a8-caf2bbad591a"},"outputs":[{"data":{"text/plain":["[category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n","probability: NEGLIGIBLE\n",", category: HARM_CATEGORY_HATE_SPEECH\n","probability: NEGLIGIBLE\n",", category: HARM_CATEGORY_HARASSMENT\n","probability: NEGLIGIBLE\n",", category: HARM_CATEGORY_DANGEROUS_CONTENT\n","probability: NEGLIGIBLE\n","]"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["response.candidates[0].safety_ratings"]},{"cell_type":"markdown","metadata":{"id":"2qt6Yj2JRf-0"},"source":["## What's next\n","\n","-   Prompt design is the process of creating prompts that elicit the desired response from language models. Writing well structured prompts is an essential part of ensuring accurate, high quality responses from a language model. Learn about best practices for [prompt writing](https://ai.google.dev/docs/prompt_best_practices).\n","-   Gemini offers several model variations to meet the needs of different use cases, such as input types and complexity, implementations for chat or other dialog language tasks, and size constraints. Learn about the available [Gemini models](https://ai.google.dev/models/gemini).\n","-   Gemini offers options for requesting [rate limit increases](https://ai.google.dev/docs/increase_quota). The rate limit for Gemini-Pro models is 60 requests per minute (RPM)."]}],"metadata":{"colab":{"name":"","provenance":[{"file_id":"1xyYW2JOxUZtCdqR-cA0P0iIfiT4cmIuV","timestamp":1713600230802},{"file_id":"1J5CVLXKcgwrl1jHUVgqb9CHfKtmxT2pL","timestamp":1713344280125},{"file_id":"https://github.com/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb","timestamp":1713275638229}],"version":""},"google":{"image_path":"/static/site-assets/images/docs/logo-python.svg","keywords":["examples","gemini","beginner","googleai","quickstart","python","text","chat","vision","embed"]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}